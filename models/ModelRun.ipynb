{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import spacy\n",
    "import pickle\n",
    "import string\n",
    "import swifter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "#set warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insya Allah, Partai Bulan Bintang akan masuk k...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gila, Dedi gak ada bosannya puji-puji Prabowo ...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CNNIndonesia Yakin sih gua Pemilu 2024 bakal ...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jangan Ada Polarisasi di Pemilu 2024, Golkar I...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@aguswkweka @pengarang_sajak @psi_id Silahkan ...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>@NMS__ampelDenta Saran saya buat bohir demo in...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ganjar Pranowo calon Presiden 2024 penerus Pre...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Gw bukan orang goblok, karena ngak dukung Yama...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Stlah bicara gagasan di @MataNajwa via @narasi...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>@temanpsi Tadinya gw tidak bergairah melihat p...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet    label\n",
       "0    Insya Allah, Partai Bulan Bintang akan masuk k...  positif\n",
       "1    Gila, Dedi gak ada bosannya puji-puji Prabowo ...  negatif\n",
       "2    @CNNIndonesia Yakin sih gua Pemilu 2024 bakal ...  negatif\n",
       "3    Jangan Ada Polarisasi di Pemilu 2024, Golkar I...  negatif\n",
       "4    @aguswkweka @pengarang_sajak @psi_id Silahkan ...  positif\n",
       "..                                                 ...      ...\n",
       "195  @NMS__ampelDenta Saran saya buat bohir demo in...  positif\n",
       "196  Ganjar Pranowo calon Presiden 2024 penerus Pre...  positif\n",
       "197  Gw bukan orang goblok, karena ngak dukung Yama...  negatif\n",
       "198  Stlah bicara gagasan di @MataNajwa via @narasi...  positif\n",
       "199  @temanpsi Tadinya gw tidak bergairah melihat p...  positif\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../database/test_data.csv'\n",
    "df = pd.read_csv(filename, encoding = 'latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, normalisasi_path='machine/preprocessing/normalisasi.csv', stopword_path='machine/preprocessing/stopword.csv'):\n",
    "        self.normalized_word_dict = self.load_normalization(normalisasi_path)\n",
    "        self.stopwords = self.load_stopwords(stopword_path)\n",
    "        self.stemmer = self.create_stemmer()\n",
    "\n",
    "    def load_normalization(self, path):\n",
    "        normalized_word = pd.read_csv(path, encoding='latin1')\n",
    "        normalized_word_dict = {}\n",
    "        for index, row in normalized_word.iterrows():\n",
    "            if row[0] not in normalized_word_dict:\n",
    "                normalized_word_dict[row[0]] = row[1]\n",
    "        return normalized_word_dict\n",
    "\n",
    "    def load_stopwords(self, path):\n",
    "        txt_stopword = pd.read_csv(path, header=None, names=[\"stopwords\"])\n",
    "        additional_stopwords = list(txt_stopword[\"stopwords\"][0].split(' '))\n",
    "        factory = StopWordRemoverFactory()\n",
    "        stopword_sastrawi = factory.get_stop_words()\n",
    "        stopword = stopword_sastrawi + additional_stopwords + [\"petrus\", \"sech\", \"bulakparen\", \"dcs\", \"mug\",\"apa\", \"dkk\", \"kek\",\"bla\",\"nihhh\",\"nyinyir\",\n",
    "                    \"background2\",\"nya\", \"klik\", \"nih\", \"wah\", \"bd\",\"cie\", \"wahh\", \"gtgt\", \"wkwkw\", \"grgr\", \"thun\", \"dong\", \"mkmk\",\"gp\",\"brengkelan\",\"woi\",\n",
    "                    \"twit\", \"iii\", \"08alian\", \"wkwkwkwk\", \"wkwk\",\"wkwkwk\", \"ah\", \"ampnbsp\", \"bawaslu\", \"hihihi\", \"hihi\", \"eh\", \"ng\",\"dl\",\"do\",\"kwkwkwkk\",\n",
    "                    \"ltpgtampnbspltpgt\", \"dancukkk\", \"yach\", \"kepl\", \"wow\",\"kretek\", \"woww\", \"smpn\", \"hmmmm\", \"hehe\", \"oooiii\",\"onana\",\"kjaernett\",\n",
    "                    \"hahaha\", \"ppp\", \"nek\", \"rang\", \"tuh\", \"pls\", \"otw\", \"pas\",\"haha\", \"ha\", \"hahahahaha\", \"hahahasenget\",\"wakakakakak\",\"wkwkwkw\",\n",
    "                    \"xixixixi\", \"hehehehee\", \"nder\", \"aduuuhhh\", \"lah\",\"lah\", \"deh\", \"si\", \"kan\", \"njirrrr\", \"huehehee\",\"yoongi\",\"sulli\",\"bjir\",\n",
    "                    \"hehehe\", \"yahh\", \"yah\", \"loh\", \"elo\", \"gw\", \"didkgkl\",\"sih\", \"lu\", \"yeyeye\", \"dlllllllllll\", \"se\",\"yoon\",\"de\",\"ruu\",\"apeeeeee\",\n",
    "                    \"pisss\", \"yo\", \"kok\", \"nge\", \"wkwkkw\", \"dah\", \"wahhh\", \"apa\", \"btw\", \"kwkwkwkwk\", \"nahh\", \"nah\", \"iya\"]\n",
    "        return stopword\n",
    "\n",
    "    def create_stemmer(self):\n",
    "        factory = StemmerFactory()\n",
    "        return factory.create_stemmer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"@\\S+\", \"\", text)\n",
    "        text = re.sub(r'(@[^\\s]+|http\\S+|#\\w+|<.*?>)', '', text)\n",
    "        text = re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        text = text.encode('ascii', 'replace').decode('ascii')\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        regexp = RegexpTokenizer(r'\\w+|\\$[0-9]+|\\S+')\n",
    "        tokens = regexp.tokenize(text)\n",
    "        return tokens\n",
    "\n",
    "    def normalized_term(self, document):\n",
    "        return [self.normalized_word_dict[term] if term in self.normalized_word_dict else term for term in document]\n",
    "\n",
    "    def filter_stopwords(self, text):\n",
    "        return [word for word in text if word not in self.stopwords]\n",
    "\n",
    "    def stemmed_wrapper(self, term):\n",
    "        return self.stemmer.stem(term)\n",
    "\n",
    "    def stemming_text(self, text):\n",
    "        return [self.stemmed_wrapper(term) for term in text]\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        tokens = self.tokenize_text(cleaned_text)\n",
    "        normalized_tokens = self.normalized_term(tokens)\n",
    "        filtered_tokens = self.filter_stopwords(normalized_tokens)\n",
    "        stemmed_tokens = self.stemming_text(filtered_tokens)\n",
    "\n",
    "        # Gabungkan hasil stemmed_tokens menjadi satu kalimat\n",
    "        processed_text = ' '.join(stemmed_tokens)\n",
    "        return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah nilai label positif menjadi 1 dan nilai negatif menjadi 0\n",
    "label_mapping = {'positif': 1, 'negatif': 0}\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "\n",
    "# Proses preprocessing data\n",
    "preprocessor = TextPreprocessor()\n",
    "df['tweet_clean'] = df['tweet'].apply(preprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Support Vector Machine With Feature Selection** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memanggil model yang digunakan\n",
    "def load_model(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "tfidf_vectorizer = load_model('machine/tfidf_vectorizer.pkl')\n",
    "feature_selector = load_model('machine/feature_selector.pkl')\n",
    "svm_classifier = load_model('machine/svm_classifier.pkl')\n",
    "\n",
    "# Mengubah tweet menjadi vektor fitur TF-IDF\n",
    "tfidf_features = tfidf_vectorizer.transform(df['tweet_clean'])\n",
    "\n",
    "# Lakukan pemilihan fitur \n",
    "selected_features = feature_selector.transform(tfidf_features)\n",
    "\n",
    "# Buat prediksi menggunakan model SVM\n",
    "predictions = svm_classifier.predict(selected_features)\n",
    "\n",
    "# Tambahkan prediksi ke DataFrame\n",
    "df['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insya Allah, Partai Bulan Bintang akan masuk k...</td>\n",
       "      <td>1</td>\n",
       "      <td>insya allah partai bulan bintang masuk parlame...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gila, Dedi gak ada bosannya puji-puji Prabowo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>gila dedi bosan pujipuji prabowo subianto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CNNIndonesia Yakin sih gua Pemilu 2024 bakal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yakin pilih bakal curang kpu lembek begini najis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jangan Ada Polarisasi di Pemilu 2024, Golkar I...</td>\n",
       "      <td>0</td>\n",
       "      <td>jangan polarisasi pilih golkar pilih lebih bai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@aguswkweka @pengarang_sajak @psi_id Silahkan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sila senang hati kalian siap teman rawan ganja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>@NMS__ampelDenta Saran saya buat bohir demo in...</td>\n",
       "      <td>1</td>\n",
       "      <td>saran buat bohir demo mending duit simpan logi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ganjar Pranowo calon Presiden 2024 penerus Pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>ganjar pranowo calon presiden terus presiden j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Gw bukan orang goblok, karena ngak dukung Yama...</td>\n",
       "      <td>0</td>\n",
       "      <td>bukan orang bodoh dukung yaman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Stlah bicara gagasan di @MataNajwa via @narasi...</td>\n",
       "      <td>1</td>\n",
       "      <td>bicara gagas via dari situ jelas pilih mantab ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>@temanpsi Tadinya gw tidak bergairah melihat p...</td>\n",
       "      <td>1</td>\n",
       "      <td>tadi gairah lihat pilih ada psi mulai semangat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  label  \\\n",
       "0    Insya Allah, Partai Bulan Bintang akan masuk k...      1   \n",
       "1    Gila, Dedi gak ada bosannya puji-puji Prabowo ...      0   \n",
       "2    @CNNIndonesia Yakin sih gua Pemilu 2024 bakal ...      0   \n",
       "3    Jangan Ada Polarisasi di Pemilu 2024, Golkar I...      0   \n",
       "4    @aguswkweka @pengarang_sajak @psi_id Silahkan ...      1   \n",
       "..                                                 ...    ...   \n",
       "195  @NMS__ampelDenta Saran saya buat bohir demo in...      1   \n",
       "196  Ganjar Pranowo calon Presiden 2024 penerus Pre...      1   \n",
       "197  Gw bukan orang goblok, karena ngak dukung Yama...      0   \n",
       "198  Stlah bicara gagasan di @MataNajwa via @narasi...      1   \n",
       "199  @temanpsi Tadinya gw tidak bergairah melihat p...      1   \n",
       "\n",
       "                                           tweet_clean  prediction  \n",
       "0    insya allah partai bulan bintang masuk parlame...           1  \n",
       "1            gila dedi bosan pujipuji prabowo subianto           0  \n",
       "2     yakin pilih bakal curang kpu lembek begini najis           0  \n",
       "3    jangan polarisasi pilih golkar pilih lebih bai...           0  \n",
       "4    sila senang hati kalian siap teman rawan ganja...           1  \n",
       "..                                                 ...         ...  \n",
       "195  saran buat bohir demo mending duit simpan logi...           1  \n",
       "196  ganjar pranowo calon presiden terus presiden j...           1  \n",
       "197                     bukan orang bodoh dukung yaman           0  \n",
       "198  bicara gagas via dari situ jelas pilih mantab ...           0  \n",
       "199     tadi gairah lihat pilih ada psi mulai semangat           0  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "   Accuracy  Precision  Recall  F1-Score  Time (s)\n",
      "0       0.9   0.908163    0.89   0.89899  0.008011\n"
     ]
    }
   ],
   "source": [
    "# Hitung matriks evaluasi\n",
    "accuracy = accuracy_score(df['label'], df['prediction'])\n",
    "precision = precision_score(df['label'], df['prediction'])\n",
    "recall = recall_score(df['label'], df['prediction'])\n",
    "f1 = f1_score(df['label'], df['prediction'])\n",
    "\n",
    "# Waktu prediksi\n",
    "start_time = time.time()\n",
    "predictions = svm_classifier.predict(selected_features)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Tambahkan prediksi ke DataFrame\n",
    "df['prediction'] = predictions\n",
    "\n",
    "# Tambahkan hasil evaluasi ke dalam DataFrame\n",
    "evaluation_results = pd.DataFrame({\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1-Score': [f1],\n",
    "    'Time (s)': [elapsed_time]\n",
    "})\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Evaluation Results:\")\n",
    "print(evaluation_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
